%!TEX program = xelatex
%# -*- coding: utf-8 -*-
%!TEX encoding = UTF-8 Unicode

\documentclass[12pt,oneside,a4paper]{article}
\usepackage{geometry}
\geometry{verbose,tmargin=2cm,bmargin=2cm,lmargin=2cm,rmargin=2cm}
\usepackage[pdfusetitle,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}
\hypersetup{pdfstartview={XYZ null null 1}}
\usepackage{url}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}
\usepackage{microtype}

\usepackage{amsmath, amsthm, amssymb, amsfonts}
\usepackage[retainorgcmds]{IEEEtrantools}

\usepackage{algorithm}
\usepackage{algorithmic}
\renewcommand{\algorithmicrequire}{\textbf{Input:}} 
\renewcommand{\algorithmicensure}{\textbf{Output:}} 

\usepackage[sc]{mathpazo}
\linespread{1.1}
\usepackage[T1]{fontenc}


\usepackage{graphics}
\usepackage{graphicx}
\usepackage[figure]{hypcap}
\usepackage[hypcap]{caption}
\usepackage{tikz}
%\usepackage{grffile} 
%\usepackage{float} 
\usepackage{pdfpages}

\usepackage{multirow}
\usepackage{booktabs}
\usepackage{threeparttable}

%\usepackage[square,numbers,super,comma,sort]{natbib}
%\usepackage[backend=biber, style=nature, sorting=none, isbn=false, url=false, doi=false]{biblatex}
%\addbibresource{ref.bib}
%\usepackage[]{authblk}

\usepackage{verbatim}
\usepackage{listings}
\usepackage{color}

\newcommand{\problem}[1]
{
    \clearpage
    \section*{Problem {#1}}
}

\newcommand{\subproblem}[1]
{
    \subsection*{Problem {#1}}
}


\newcommand{\solution}
{
    \vspace{15pt}
    \noindent\ignorespaces\textbf{\large Solution}\par
}

\usepackage{fancyhdr}
\usepackage{extramarks}
\lhead{\hmwkAuthorName}
\chead{\hmwkTitle}
\rhead{\firstxmark}
\cfoot{\thepage}

\newcommand{\hmwkTitle}{CSCI 5304 HW 3}
\newcommand{\hmwkAuthorName}{Jingxiang Li}

\setlength\headheight{15pt}
\setlength\parindent{0pt}
\setlength{\parskip}{0.5em}

\newcommand{\m}[1]{\texttt{{#1}}}


\pagestyle{fancy}

\title{\hmwkTitle}
\author{\hmwkAuthorName}
\date{\today}

\begin{document}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{ %
  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
  basicstyle=\small\ttfamily,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  deletekeywords={...},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  frame=single,                    % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=Octave,                 % the language of the code
  morekeywords={*,...},            % if you want to add more keywords to the set
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=10pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=1,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=2,                       % sets default tabsize to 2 spaces
  title=\lstname,                   % show the filename of files included with \lstinputlisting; also try caption instead of title
  aboveskip=\baselineskip, 
  belowskip=-1 \baselineskip
}


\maketitle


\problem{1}
Consider the matrices $$A = \begin{pmatrix}
  1 & -1 \\
  1 & -1.00001
 \end{pmatrix} \quad B = \begin{pmatrix}
   1 & -1 \\
  -1 & 1.00001
  \end{pmatrix}$$

What is ratio of the largest to smallest eigenvalues (in modulus) for $A$ and for $B$? Show that $k_{2}(A) = k_{2}(B)$. What can you conclude about the ratio of the largest to smallest eigenvalues as a way of estimating sensitivity of a linear system? Would you consider $A$ to be well-conditioned or ill-conditioned?

\solution

First, let's see the ratio of the largest to smallest eigenvalues (in modulus) for $A$ and for $B$.

\begin{lstlisting}
A = [1, -1; 1, -1.00001];
B = [1, -1; -1, 1.00001];
eig_A = eig(A);
eig_B = eig(B);
max(abs(eig_A)) / min(abs(eig_A))
% > 1.0032
max(abs(eig_B)) / min(abs(eig_B))
% > 4.0000e+05
\end{lstlisting}

Note that the ratio for $A$ is $1.0032$, which is much smaller than $B$'s ratio $4.0000e+05$.

Then, we show that $k_{2}(A) = k_{2}(B)$ by using SVD decomposition and \m{Matlab} function \m{cond}.

\begin{lstlisting}
max(svd(A)) / min(svd(A))
% > 4.0000e+05
max(svd(B)) / min(svd(B))
% > 4.0000e+05

cond(A, 2)
% > 4.0000e+05
cond(B, 2)
% > 4.0000e+05
\end{lstlisting}

Note that both SVD and function \m{cond} show that $k_{2}(A) = k_{2}(B)$.

We can conclude that the ratio of the largest to smallest eigenvalues is not a robust way of estimating sensitivity of a linear system. 

Further, I won't consider $A$ to be well-conditioned for the following two reasons: 
\begin{enumerate}
  \item SVD and function \m{cond} show that the condition number of $A$ is very large.
  \item $-1.00001$ is so close to $-1$, and if we see it as $-1$ matrix A become singular, so that A is obviously ill-conditioned.
\end{enumerate}

\problem{2}

\subproblem{a}
Find the $LU$ factorization of the matrix:
$$A = \begin{pmatrix}
2 & 0 & 5 & 8\\
0 & 2 & -1 & -3\\
-2 & 6 & 2 & -3\\
4 & -4 & 0 & 2
\end{pmatrix}$$

\solution
Here we define a function \m{LU\_nopvt} for $LU$ decomposition without partial pivoting for square matrix.

\begin{lstlisting}
%%  LU_nopvt: LU decomposition without partial pivoting using Gaussian Transformation
%%  Input:      A, square matrix recommended
%%  Output:     L U, L is lower-triangular, U is upper-triangular.

function [L U] = LU_nopvt(A)
    
    n = size(A);
    n = n(1);
    
    M = eye(size(A));
    L = eye(size(A));

    for k = 1 : (n - 1)
        gamma = zeros(n, 1);
        for i = (k + 1) : n
            gamma(i) = A(i, k) ./ A(k, k);
        end
        tmp = zeros(n, 1);
        tmp(k) = 1;
        M = eye(n) - gamma * tmp';
        A = M * A;
        L = L * (eye(n) + gamma * tmp');
    end

    U = A;
end
\end{lstlisting}
\clearpage
Then we apply function \m{LU\_nopvt} to matrix $A$.

\begin{lstlisting}
A = [2, 0, 5, 8; 0, 2, -1, -3; -2, 6, 2, -3; 4, -4, 0, 2];
[L U] = LU_nopvt(A);

L
% >  1.0000         0         0         0
% >  0         1.0000         0         0
% > -1.0000    3.0000    1.0000         0
% >  2.0000   -2.0000   -1.2000    1.0000

U
% >  2.0000         0    5.0000    8.0000
% >       0    2.0000   -1.0000   -3.0000
% >       0         0   10.0000   14.0000
% >       0         0         0   -3.2000
\end{lstlisting}

\subproblem{b}
Find the $PA=LU$ factorization of $A$ using partial pivoting.

\solution
\begin{lstlisting}
[L,U,P] = lu(A);

L
% >  1.0000         0         0         0
% > -0.5000    1.0000         0         0
% >  0.5000    0.5000    1.0000         0
% >  0         0.5000   -0.5000    1.0000

U
% > 4    -4     0     2
% > 0     4     2    -2
% > 0     0     4     8
% > 0     0     0     2

P
% > 0     0     0     1
% > 0     0     1     0
% > 1     0     0     0
% > 0     1     0     0
\end{lstlisting}

\subproblem{c}
What is the determinant of $A$?

\solution
Given $PA = LU$, we have $$det(A) = \frac{det(L)det(U)}{det(P)}$$
it's easy to see that $det(L) = 1$, $det(U) = \prod_{i = 1}^{4}{U_{ii}} = 128$, $det(P) = -1$, so that $$det(A) = 128 / -1 = -128$$

\subproblem{d}
Using the $LU$ factors obtained in (a) find the second column of the inverse of $A$, without computing the whole inverse.

\solution
Note that
$$A^{-1} \cdot (0, 1, 0, 0)^{T} = A^{-1}_{2}$$
then let $x = A^{-1}_{2}$, $b = (0, 1, 0, 0)^{T}$, We have 
$Ax = b$, i.e. $LUx = b$. To obtain x, we first solve $Ly = b$, then $Ux = y$. 

We first define two functions \m{Forw\_sub} and \m{Back\_sub} for forward substitution and backward substitution.

\begin{lstlisting}
%%  Back_sub: Backward substitution to solve Ax = b where A is upper-triangular
%%  Input: A, b
%%  Output: x
function [x] = Back_sub(A, b)
    n = length(b);
    foo = 0;

    for i = n : -1 : 2
        for j = (i - 1) : -1 : 1
            foo = A(j, i) ./ A(i, i);
            A(j, :) = A(j, :) - foo * A(i, :);
            b(j) = b(j) - foo * b(i);
        end
    end

    x = b ./ diag(A);
end
\end{lstlisting}

\begin{lstlisting}
%%  Forw_sub: Forward substitution to solve Ax = b where A is lower-triangular
%%  Input: A, b
%%  Output: x
function [x] = Forw_sub(A, b)    
    n = length(b);
    foo = 0;

    for i = 1 : (n - 1)
        for j = (i + 1) : n
            foo = A(j, i) ./ A(i, i);
            A(j, :) = A(j, :) - foo * A(i, :);
            b(j) = b(j) - foo * b(i);
        end
    end

    x = b ./ diag(A);    
end
\end{lstlisting}

Then we apply \m{Forw\_sub} and \m{Back\_sub} to the $LU$ decomposition result, to obtain the second column of the inverse of $A$.

\begin{lstlisting}
[L U] = LU_nopvt(A);
b = [0, 1, 0 ,0]';
y = Forw_sub(L, b);
x = Back_sub(U, y);

x
% >  0.5000
% >  0.7500
% > -1.0000
% >  0.5000
\end{lstlisting}

\problem{3}

\subproblem{a}
Show that if $A$ is Symmetric Positive Definite (SPD) then $Trace(AX) > 0$ for all SPD matrices $X$.

\solution
We calculate Cholesky decomposition for $A$ and $X$, say $A = L_{A}L_{A}^{T}$, $X = L_{X}L_{X}^{T}$, then
$$Trace(AX) = Trace(L_{A}L_{A}^{T}L_{X}L_{X}^{T}) = Trace(L_{A}^{T}L_{X}L_{X}^{T}L_{A})$$
let $M = L_{A}^{T}L_{X}$, then 
$$Trace(AX) = Trace(MM^{T})$$
Let $M = (M_{1}, M_{2}, M_{3}, M_{4})^{T}$, then 
$$Trace(MM^{T}) = \sum_{i = 1}^{4}(||M_{1}||_{2}^{2}) > 0 $$
Q.E.D.

\subproblem{b}
Show that if $Trace(AX) \geq 0$ for all Symmetric Positive Semi-Definite (PSD) matrices $X$ then $A$ is PSD.

\solution
We first decompose $X = LL^{T}$, then
$$Trace(AX) = Trace(ALL^{T}) = Trace(L^{T}AL)$$
$L$ is a lower-triangular matrix, Let $L = (L_{1},\dots,L_{n})$. Then
$$Trace(AX) = L_{1}^{T}AL_{1} + L_{2}^{T}AL_{2} + \dots + L_{3}^{T}AL_{3} \geq 0$$
We will then prove it by contradiction. Suppose A is not PSD, then $\exists x~~s.t.~~x^{T}Ax < 0$. then we can construct $L^{*} = (x, 0, 0, \dots)$ and let $X^{*} = L^{*}{L^{*}}^{T}$, then $Trace(AX^{*}) =  x^{T}Ax < 0$, contradiction. So that A is PSD.\par Q.E.D.


\end{document}